{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGLxLGctlIuELnLFd39OYG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k-ganda/database_design_pld5/blob/main/database_design.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import requests\n",
        "import joblib\n",
        "from typing import Dict, Optional, Any\n",
        "import logging\n",
        "import time\n",
        "from requests.adapters import HTTPAdapter\n",
        "from urllib3.util.retry import Retry\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "class UserBehaviorPredictor:\n",
        "    def __init__(self, random_state: int = 42):\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "        self.random_state = random_state\n",
        "        self.model = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.feature_names = None\n",
        "\n",
        "        # Configure retry strategy for API requests\n",
        "        self.session = requests.Session()\n",
        "        retry_strategy = Retry(\n",
        "            total=3,\n",
        "            backoff_factor=1,\n",
        "            status_forcelist=[500, 502, 503, 504]\n",
        "        )\n",
        "        self.session.mount('http://', HTTPAdapter(max_retries=retry_strategy))\n",
        "\n",
        "    def load_dataset(self, filepath: str) -> None:\n",
        "        \"\"\"Load and validate the dataset\"\"\"\n",
        "        try:\n",
        "            self.logger.info(\"Loading dataset...\")\n",
        "            self.df = pd.read_csv(filepath)\n",
        "            self._validate_dataset()\n",
        "            self.logger.info(f\"Dataset loaded with shape: {self.df.shape}\")\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error loading dataset: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _validate_dataset(self) -> None:\n",
        "        \"\"\"Validate dataset structure and contents\"\"\"\n",
        "        required_columns = {\n",
        "            'User ID', 'User Behavior Class', 'App Usage Time (min/day)',\n",
        "            'Screen On Time (hours/day)', 'Battery Drain (mAh/day)',\n",
        "            'Number of Apps Installed', 'Data Usage (MB/day)', 'Age',\n",
        "            'Device Model', 'Operating System', 'Gender'\n",
        "        }\n",
        "\n",
        "        missing_columns = required_columns - set(self.df.columns)\n",
        "        if missing_columns:\n",
        "            raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
        "\n",
        "        # Check for null values\n",
        "        null_counts = self.df.isnull().sum()\n",
        "        if null_counts.any():\n",
        "            self.logger.warning(f\"Found null values:\\n{null_counts[null_counts > 0]}\")\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \"\"\"Prepare data for training with improved error handling\"\"\"\n",
        "        self.logger.info(\"Preparing data...\")\n",
        "        try:\n",
        "            X = self.df.drop(['User ID', 'User Behavior Class'], axis=1)\n",
        "            y = self.df['User Behavior Class']\n",
        "\n",
        "            # Handle categorical variables\n",
        "            categorical_columns = ['Device Model', 'Operating System', 'Gender']\n",
        "            X = pd.get_dummies(X, columns=categorical_columns)\n",
        "\n",
        "            # Scale numerical features with error checking\n",
        "            numerical_cols = [\n",
        "                'App Usage Time (min/day)', 'Screen On Time (hours/day)',\n",
        "                'Battery Drain (mAh/day)', 'Number of Apps Installed',\n",
        "                'Data Usage (MB/day)', 'Age'\n",
        "            ]\n",
        "\n",
        "            # Check for infinite or null values\n",
        "            if X[numerical_cols].isin([np.inf, -np.inf]).any().any():\n",
        "                self.logger.warning(\"Infinite values found in numerical columns\")\n",
        "                X[numerical_cols] = X[numerical_cols].replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "            X[numerical_cols] = self.scaler.fit_transform(X[numerical_cols])\n",
        "            self.feature_names = X.columns\n",
        "\n",
        "            return X, y\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in data preparation: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def train_model(self):\n",
        "        \"\"\"Train model with improved hyperparameters and validation\"\"\"\n",
        "        try:\n",
        "            X, y = self.prepare_data()\n",
        "\n",
        "            # Split the data\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X, y, test_size=0.2, random_state=self.random_state\n",
        "            )\n",
        "\n",
        "            # Initialize model with better parameters to prevent overfitting\n",
        "            self.model = RandomForestClassifier(\n",
        "                n_estimators=100,\n",
        "                max_depth=None,  # Let trees grow fully\n",
        "                min_samples_split=5,  # Minimum samples required to split\n",
        "                min_samples_leaf=2,   # Minimum samples required at leaf node\n",
        "                max_features='sqrt',  # Use sqrt of features for each split\n",
        "                random_state=self.random_state,\n",
        "                class_weight='balanced'  # Handle class imbalance\n",
        "            )\n",
        "\n",
        "            # Perform cross-validation\n",
        "            self.logger.info(\"Running cross-validation...\")\n",
        "            cv_scores = cross_val_score(self.model, X_train, y_train, cv=5)\n",
        "            self.logger.info(f\"Cross-validation scores: {cv_scores}\")\n",
        "            self.logger.info(f\"Mean CV accuracy: {np.mean(cv_scores):.3f} Â± {np.std(cv_scores):.3f}\")\n",
        "\n",
        "            # Train the model\n",
        "            self.logger.info(\"Training model...\")\n",
        "            self.model.fit(X_train, y_train)\n",
        "\n",
        "            # Evaluate model\n",
        "            train_score = self.model.score(X_train, y_train)\n",
        "            test_score = self.model.score(X_test, y_test)\n",
        "            self.logger.info(f\"Training accuracy: {train_score:.3f}\")\n",
        "            self.logger.info(f\"Testing accuracy: {test_score:.3f}\")\n",
        "\n",
        "            # Generate detailed classification report\n",
        "            y_pred = self.model.predict(X_test)\n",
        "            self.logger.info(\"\\nClassification Report:\")\n",
        "            self.logger.info(f\"\\n{classification_report(y_test, y_pred)}\")\n",
        "\n",
        "            # Save model artifacts\n",
        "            self._save_model()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in model training: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _save_model(self) -> None:\n",
        "        \"\"\"Save model and associated artifacts\"\"\"\n",
        "        try:\n",
        "            joblib.dump(self.model, 'user_behavior_rf_model.joblib')\n",
        "            joblib.dump(self.scaler, 'scaler.joblib')\n",
        "            joblib.dump(self.feature_names, 'feature_names.joblib')\n",
        "            self.logger.info(\"Model artifacts saved successfully\")\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error saving model artifacts: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def fetch_latest_entry(self, api_url: str = \"http://localhost:8000/userbehaviors\",\n",
        "                          timeout: int = 5) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Fetch latest entry with improved error handling and timeout\"\"\"\n",
        "        self.logger.info(\"Fetching latest entry from API...\")\n",
        "        try:\n",
        "            response = self.session.get(api_url, timeout=timeout)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "            self.logger.info(\"Latest entry fetched successfully\")\n",
        "            return data\n",
        "        except requests.exceptions.ConnectionError:\n",
        "            self.logger.error(f\"Connection error: Could not connect to {api_url}\")\n",
        "        except requests.exceptions.Timeout:\n",
        "            self.logger.error(\"Request timed out\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            self.logger.error(f\"Error fetching data: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    def predict(self, input_data: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Make prediction with improved error handling and validation\"\"\"\n",
        "        try:\n",
        "            # Load model if not already loaded\n",
        "            if not self.model:\n",
        "                self._load_model()\n",
        "\n",
        "            # Prepare and validate input\n",
        "            prepared_data = self._prepare_prediction_input(input_data)\n",
        "\n",
        "            # Make prediction\n",
        "            prediction = self.model.predict(prepared_data)\n",
        "            probabilities = self.model.predict_proba(prepared_data)\n",
        "\n",
        "            # Calculate confidence\n",
        "            confidence = np.max(probabilities) * 100\n",
        "\n",
        "            result = {\n",
        "                'predicted_class': int(prediction[0]),\n",
        "                'confidence': f\"{confidence:.2f}%\",\n",
        "                'probabilities': {\n",
        "                    f\"Class {i}\": f\"{prob:.2f}%\"\n",
        "                    for i, prob in enumerate(probabilities[0])\n",
        "                }\n",
        "            }\n",
        "\n",
        "            self.logger.info(f\"Prediction made with confidence: {confidence:.2f}%\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error making prediction: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _load_model(self) -> None:\n",
        "        \"\"\"Load saved model and artifacts\"\"\"\n",
        "        try:\n",
        "            self.model = joblib.load('user_behavior_rf_model.joblib')\n",
        "            self.scaler = joblib.load('scaler.joblib')\n",
        "            self.feature_names = joblib.load('feature_names.joblib')\n",
        "            self.logger.info(\"Model loaded successfully\")\n",
        "        except FileNotFoundError:\n",
        "            self.logger.error(\"Model files not found. Please train the model first.\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error loading model: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    predictor = UserBehaviorPredictor()\n",
        "\n",
        "    try:\n",
        "        # Load and train model\n",
        "        predictor.load_dataset('user_behavior_dataset.csv')\n",
        "        predictor.train_model()\n",
        "\n",
        "        # Attempt to fetch and process latest entry\n",
        "        latest_entry = predictor.fetch_latest_entry()\n",
        "        if latest_entry:\n",
        "            result = predictor.predict(latest_entry)\n",
        "            predictor.logger.info(\"Prediction result:\", result)\n",
        "        else:\n",
        "            predictor.logger.warning(\"No data available for prediction\")\n",
        "\n",
        "    except Exception as e:\n",
        "        predictor.logger.error(f\"Application error: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4zQ4CCXweRr",
        "outputId": "1d75bfc6-73a7-43b0-97cc-74a0447a1a25"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7e8d49acf700>: Failed to establish a new connection: [Errno 111] Connection refused')': /userbehaviors\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7e8d49acf430>: Failed to establish a new connection: [Errno 111] Connection refused')': /userbehaviors\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7e8d49acc1c0>: Failed to establish a new connection: [Errno 111] Connection refused')': /userbehaviors\n",
            "ERROR:__main__:Connection error: Could not connect to http://localhost:8000/userbehaviors\n",
            "WARNING:__main__:No data available for prediction\n"
          ]
        }
      ]
    }
  ]
}