{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBDHwxHh+/SF5+opajS28G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k-ganda/database_design_pld5/blob/main/database_design.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "import requests\n",
        "import joblib\n",
        "\n",
        "class UserBehaviorPredictor:\n",
        "    def __init__(self):\n",
        "        # Load the dataset\n",
        "        print(\"Loading dataset...\")\n",
        "        self.df = pd.read_csv('user_behavior_dataset.csv')\n",
        "        print(\"Dataset loaded with shape:\", self.df.shape)\n",
        "\n",
        "        # Initialize model and scaler\n",
        "        self.model = None\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def prepare_data(self):\n",
        "        # Separate features and target\n",
        "        print(\"Preparing data...\")\n",
        "        X = self.df.drop(['User ID', 'User Behavior Class'], axis=1)\n",
        "        y = self.df['User Behavior Class']\n",
        "\n",
        "        # Convert categorical variables\n",
        "        X = pd.get_dummies(X, columns=['Device Model', 'Operating System', 'Gender'])\n",
        "        print(\"Categorical columns converted.\")\n",
        "\n",
        "        # Scale numerical features\n",
        "        numerical_cols = [\n",
        "            'App Usage Time (min/day)', 'Screen On Time (hours/day)',\n",
        "            'Battery Drain (mAh/day)', 'Number of Apps Installed',\n",
        "            'Data Usage (MB/day)', 'Age'\n",
        "        ]\n",
        "        X[numerical_cols] = self.scaler.fit_transform(X[numerical_cols])\n",
        "        print(\"Numerical columns scaled.\")\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def train_model(self):\n",
        "        # Prepare data\n",
        "        X, y = self.prepare_data()\n",
        "\n",
        "        # Split the data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42\n",
        "        )\n",
        "        print(\"Data split into training and testing sets.\")\n",
        "\n",
        "        # Initialize Random Forest model\n",
        "        self.model = RandomForestClassifier(\n",
        "            n_estimators=100,\n",
        "            max_depth=10,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        # Cross-validation to assess overfitting\n",
        "        print(\"Running cross-validation for model accuracy...\")\n",
        "        cv_scores = cross_val_score(self.model, X_train, y_train, cv=5)\n",
        "        print(f\"Cross-validation scores: {cv_scores}\")\n",
        "        print(f\"Mean cross-validation accuracy: {np.mean(cv_scores):.3f}\")\n",
        "\n",
        "        # Train the model\n",
        "        print(\"Training model...\")\n",
        "        self.model.fit(X_train, y_train)\n",
        "\n",
        "        # Print model performance\n",
        "        train_score = self.model.score(X_train, y_train)\n",
        "        test_score = self.model.score(X_test, y_test)\n",
        "        print(f\"Training accuracy: {train_score:.3f}\")\n",
        "        print(f\"Testing accuracy: {test_score:.3f}\")\n",
        "\n",
        "        # Save the model and scaler\n",
        "        joblib.dump(self.model, 'user_behavior_rf_model.joblib')\n",
        "        joblib.dump(self.scaler, 'scaler.joblib')\n",
        "        print(\"Model and scaler saved.\")\n",
        "\n",
        "    def fetch_latest_entry(self, api_url=\"https://database-design-pld5.onrender.com/docs#/\"):\n",
        "        \"\"\"\n",
        "        Fetch the latest entry from the API\n",
        "        \"\"\"\n",
        "        print(\"Fetching the latest entry from API...\")\n",
        "        try:\n",
        "            response = requests.get(api_url)\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                print(\"Latest entry fetched:\", data)\n",
        "                return data\n",
        "            else:\n",
        "                print(f\"Error fetching data: {response.status_code}\")\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            print(f\"Error connecting to API: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def prepare_input_data(self, input_data):\n",
        "        \"\"\"\n",
        "        Prepare a single input entry for prediction\n",
        "        \"\"\"\n",
        "        # Convert input to DataFrame\n",
        "        input_df = pd.DataFrame([input_data])\n",
        "        print(\"Input data converted to DataFrame.\")\n",
        "\n",
        "        # Drop User ID if present\n",
        "        if 'User ID' in input_df.columns:\n",
        "            input_df = input_df.drop('User ID', axis=1)\n",
        "\n",
        "        # Create dummy variables\n",
        "        input_df = pd.get_dummies(input_df, columns=['Device Model', 'Operating System', 'Gender'])\n",
        "\n",
        "        # Ensure all columns from training are present\n",
        "        for col in self.model.feature_names_in_:\n",
        "            if col not in input_df.columns:\n",
        "                input_df[col] = 0\n",
        "\n",
        "        # Reorder columns to match training data\n",
        "        input_df = input_df[self.model.feature_names_in_]\n",
        "        print(\"Input data prepared for prediction.\")\n",
        "\n",
        "        return input_df\n",
        "\n",
        "    def predict(self, input_data):\n",
        "        \"\"\"\n",
        "        Make prediction for new input data\n",
        "        \"\"\"\n",
        "        # Prepare input data\n",
        "        prepared_data = self.prepare_input_data(input_data)\n",
        "\n",
        "        # Load the model and scaler if not already loaded\n",
        "        if not self.model:\n",
        "            print(\"Loading pre-trained model and scaler...\")\n",
        "            self.model = joblib.load('user_behavior_rf_model.joblib')\n",
        "            self.scaler = joblib.load('scaler.joblib')\n",
        "\n",
        "        # Make prediction\n",
        "        prediction = self.model.predict(prepared_data)\n",
        "        probabilities = self.model.predict_proba(prepared_data)\n",
        "\n",
        "        # Get prediction confidence\n",
        "        confidence = np.max(probabilities) * 100\n",
        "        print(f\"Prediction made with confidence: {confidence:.2f}%\")\n",
        "\n",
        "        return {\n",
        "            'predicted_class': int(prediction[0]),\n",
        "            'confidence': f\"{confidence:.2f}%\",\n",
        "            'probabilities': {f\"Class {i}\": f\"{prob:.2f}%\"\n",
        "                            for i, prob in enumerate(probabilities[0])}\n",
        "        }\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    predictor = UserBehaviorPredictor()\n",
        "    predictor.train_model()\n",
        "    latest_entry = predictor.fetch_latest_entry()\n",
        "\n",
        "    if latest_entry:\n",
        "        result = predictor.predict(latest_entry)\n",
        "        print(\"Prediction result:\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4zQ4CCXweRr",
        "outputId": "91ab5fc1-0211-456d-845d-84e8ce47e516"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Dataset loaded with shape: (700, 11)\n",
            "Preparing data...\n",
            "Categorical columns converted.\n",
            "Numerical columns scaled.\n",
            "Data split into training and testing sets.\n",
            "Running cross-validation for model accuracy...\n",
            "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
            "Mean cross-validation accuracy: 1.000\n",
            "Training model...\n",
            "Training accuracy: 1.000\n",
            "Testing accuracy: 1.000\n",
            "Model and scaler saved.\n",
            "Fetching the latest entry from API...\n",
            "Error connecting to API: Expecting value: line 2 column 5 (char 5)\n"
          ]
        }
      ]
    }
  ]
}