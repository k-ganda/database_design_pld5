{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/k-ganda/database_design_pld5/blob/main/database_design.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F4zQ4CCXweRr",
    "outputId": "764543b6-227c-4378-d3a4-979c122362f1"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import requests\n",
    "import joblib\n",
    "\n",
    "class UserBehaviorPredictor:\n",
    "    def __init__(self):\n",
    "        # Load the dataset\n",
    "        print(\"Loading dataset...\")\n",
    "        self.df = pd.read_csv('user_behavior_dataset.csv')\n",
    "        print(\"Dataset loaded with shape:\", self.df.shape)\n",
    "\n",
    "        # Initialize model and scaler\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # Separate features and target\n",
    "        print(\"Preparing data...\")\n",
    "        X = self.df.drop(['User ID', 'User Behavior Class'], axis=1)\n",
    "        y = self.df['User Behavior Class']\n",
    "\n",
    "        # Convert categorical variables\n",
    "        X = pd.get_dummies(X, columns=['Device Model', 'Operating System', 'Gender'])\n",
    "        print(\"Categorical columns converted.\")\n",
    "\n",
    "        # Scale numerical features\n",
    "        numerical_cols = [\n",
    "            'App Usage Time (min/day)', 'Screen On Time (hours/day)',\n",
    "            'Battery Drain (mAh/day)', 'Number of Apps Installed',\n",
    "            'Data Usage (MB/day)', 'Age'\n",
    "        ]\n",
    "        X[numerical_cols] = self.scaler.fit_transform(X[numerical_cols])\n",
    "        print(\"Numerical columns scaled.\")\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def train_model(self):\n",
    "        # Prepare data\n",
    "        X, y = self.prepare_data()\n",
    "\n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        print(\"Data split into training and testing sets.\")\n",
    "\n",
    "        # Initialize Random Forest model\n",
    "        self.model = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Cross-validation to assess overfitting\n",
    "        print(\"Running cross-validation for model accuracy...\")\n",
    "        cv_scores = cross_val_score(self.model, X_train, y_train, cv=5)\n",
    "        print(f\"Cross-validation scores: {cv_scores}\")\n",
    "        print(f\"Mean cross-validation accuracy: {np.mean(cv_scores):.3f}\")\n",
    "\n",
    "        # Train the model\n",
    "        print(\"Training model...\")\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "        # Print model performance\n",
    "        train_score = self.model.score(X_train, y_train)\n",
    "        test_score = self.model.score(X_test, y_test)\n",
    "        print(f\"Training accuracy: {train_score:.3f}\")\n",
    "        print(f\"Testing accuracy: {test_score:.3f}\")\n",
    "\n",
    "        # Save the model and scaler\n",
    "        joblib.dump(self.model, 'user_behavior_rf_model.joblib')\n",
    "        joblib.dump(self.scaler, 'scaler.joblib')\n",
    "        print(\"Model and scaler saved.\")\n",
    "\n",
    "    def fetch_latest_entry(self, api_url=\"http://localhost:8000/\"):\n",
    "        \"\"\"\n",
    "        Fetch the latest entry from the API\n",
    "        \"\"\"\n",
    "        print(\"Fetching the latest entry from API...\")\n",
    "        try:\n",
    "            response = requests.get(api_url)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                print(\"Latest entry fetched:\", data)\n",
    "                return data\n",
    "            else:\n",
    "                print(f\"Error fetching data: {response.status_code}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error connecting to API: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def prepare_input_data(self, input_data):\n",
    "        \"\"\"\n",
    "        Prepare a single input entry for prediction\n",
    "        \"\"\"\n",
    "        # Convert input to DataFrame\n",
    "        input_df = pd.DataFrame([input_data])\n",
    "        print(\"Input data converted to DataFrame.\")\n",
    "\n",
    "        # Drop User ID if present\n",
    "        if 'User ID' in input_df.columns:\n",
    "            input_df = input_df.drop('User ID', axis=1)\n",
    "\n",
    "        # Create dummy variables\n",
    "        input_df = pd.get_dummies(input_df, columns=['Device Model', 'Operating System', 'Gender'])\n",
    "\n",
    "        # Ensure all columns from training are present\n",
    "        for col in self.model.feature_names_in_:\n",
    "            if col not in input_df.columns:\n",
    "                input_df[col] = 0\n",
    "\n",
    "        # Reorder columns to match training data\n",
    "        input_df = input_df[self.model.feature_names_in_]\n",
    "        print(\"Input data prepared for prediction.\")\n",
    "\n",
    "        return input_df\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        \"\"\"\n",
    "        Make prediction for new input data\n",
    "        \"\"\"\n",
    "        # Prepare input data\n",
    "        prepared_data = self.prepare_input_data(input_data)\n",
    "\n",
    "        # Load the model and scaler if not already loaded\n",
    "        if not self.model:\n",
    "            print(\"Loading pre-trained model and scaler...\")\n",
    "            self.model = joblib.load('user_behavior_rf_model.joblib')\n",
    "            self.scaler = joblib.load('scaler.joblib')\n",
    "\n",
    "        # Make prediction\n",
    "        prediction = self.model.predict(prepared_data)\n",
    "        probabilities = self.model.predict_proba(prepared_data)\n",
    "\n",
    "        # Get prediction confidence\n",
    "        confidence = np.max(probabilities) * 100\n",
    "        print(f\"Prediction made with confidence: {confidence:.2f}%\")\n",
    "\n",
    "        return {\n",
    "            'predicted_class': int(prediction[0]),\n",
    "            'confidence': f\"{confidence:.2f}%\",\n",
    "            'probabilities': {f\"Class {i}\": f\"{prob:.2f}%\"\n",
    "                            for i, prob in enumerate(probabilities[0])}\n",
    "        }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = UserBehaviorPredictor()\n",
    "    predictor.train_model()\n",
    "    latest_entry = predictor.fetch_latest_entry()\n",
    "\n",
    "    if latest_entry:\n",
    "        result = predictor.predict(latest_entry)\n",
    "        print(\"Prediction result:\", result)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMXvTpC7LrHQCSY1R6iiLX3",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
